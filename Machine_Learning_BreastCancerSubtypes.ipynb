{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"C:/Users/Mahmood/Desktop/Final_DataSet/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/RNA-seq_BreastDataStructured1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>Class</th>\n",
       "      <th>ARHGEF10L</th>\n",
       "      <th>HIF3A</th>\n",
       "      <th>RNF17</th>\n",
       "      <th>RNF10</th>\n",
       "      <th>RNF11</th>\n",
       "      <th>RNF13</th>\n",
       "      <th>GTF2IP1</th>\n",
       "      <th>REM1</th>\n",
       "      <th>...</th>\n",
       "      <th>TULP2</th>\n",
       "      <th>NPY5R</th>\n",
       "      <th>GNGT2</th>\n",
       "      <th>GNGT1</th>\n",
       "      <th>TULP3</th>\n",
       "      <th>PTRF</th>\n",
       "      <th>BCL6B</th>\n",
       "      <th>GSTK1</th>\n",
       "      <th>SELP</th>\n",
       "      <th>SELS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-A8-A092-01</td>\n",
       "      <td>LumB</td>\n",
       "      <td>470.613860</td>\n",
       "      <td>1.294325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4032.615110</td>\n",
       "      <td>1501.407625</td>\n",
       "      <td>1583.498736</td>\n",
       "      <td>4522.798478</td>\n",
       "      <td>3.354040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.294325</td>\n",
       "      <td>15.124337</td>\n",
       "      <td>1.294325</td>\n",
       "      <td>665.733058</td>\n",
       "      <td>2922.120588</td>\n",
       "      <td>136.352751</td>\n",
       "      <td>1046.749127</td>\n",
       "      <td>15.124337</td>\n",
       "      <td>711.342228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-A7-A0CE-11</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1022.581418</td>\n",
       "      <td>71.476644</td>\n",
       "      <td>18.142483</td>\n",
       "      <td>3556.148857</td>\n",
       "      <td>2387.690290</td>\n",
       "      <td>1341.284905</td>\n",
       "      <td>6638.768825</td>\n",
       "      <td>67.033019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.634897</td>\n",
       "      <td>16.872478</td>\n",
       "      <td>35.919615</td>\n",
       "      <td>1.317497</td>\n",
       "      <td>654.976802</td>\n",
       "      <td>14108.725020</td>\n",
       "      <td>259.735608</td>\n",
       "      <td>3730.103638</td>\n",
       "      <td>694.966680</td>\n",
       "      <td>1163.213337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-D8-A1JK-01</td>\n",
       "      <td>Basal</td>\n",
       "      <td>499.866835</td>\n",
       "      <td>3.858928</td>\n",
       "      <td>1.952876</td>\n",
       "      <td>3154.728205</td>\n",
       "      <td>3317.774228</td>\n",
       "      <td>1173.579614</td>\n",
       "      <td>3601.794112</td>\n",
       "      <td>15.294065</td>\n",
       "      <td>...</td>\n",
       "      <td>1.476519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.689742</td>\n",
       "      <td>2.429400</td>\n",
       "      <td>584.192489</td>\n",
       "      <td>6826.829473</td>\n",
       "      <td>469.864187</td>\n",
       "      <td>5993.986005</td>\n",
       "      <td>13.388292</td>\n",
       "      <td>1184.120347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-BH-A0AY-11</td>\n",
       "      <td>Normal</td>\n",
       "      <td>871.888597</td>\n",
       "      <td>211.439338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3402.784330</td>\n",
       "      <td>3406.560232</td>\n",
       "      <td>1826.163218</td>\n",
       "      <td>6768.404146</td>\n",
       "      <td>91.000338</td>\n",
       "      <td>...</td>\n",
       "      <td>1.434751</td>\n",
       "      <td>101.871028</td>\n",
       "      <td>13.173803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>768.392699</td>\n",
       "      <td>23292.857250</td>\n",
       "      <td>789.721414</td>\n",
       "      <td>2264.536378</td>\n",
       "      <td>645.333004</td>\n",
       "      <td>943.579327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-E2-A10C-01</td>\n",
       "      <td>LumB</td>\n",
       "      <td>823.542903</td>\n",
       "      <td>1.475701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3785.583565</td>\n",
       "      <td>1471.936787</td>\n",
       "      <td>604.710157</td>\n",
       "      <td>11215.450880</td>\n",
       "      <td>9.087604</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475701</td>\n",
       "      <td>1.475701</td>\n",
       "      <td>17.174545</td>\n",
       "      <td>1.475701</td>\n",
       "      <td>524.791303</td>\n",
       "      <td>3105.263544</td>\n",
       "      <td>229.348872</td>\n",
       "      <td>2363.976535</td>\n",
       "      <td>27.165430</td>\n",
       "      <td>981.469755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>TCGA-BH-A0BJ-01</td>\n",
       "      <td>LumA</td>\n",
       "      <td>756.292237</td>\n",
       "      <td>3.510557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3534.278468</td>\n",
       "      <td>2569.549982</td>\n",
       "      <td>1138.643179</td>\n",
       "      <td>8383.285226</td>\n",
       "      <td>23.954088</td>\n",
       "      <td>...</td>\n",
       "      <td>1.717250</td>\n",
       "      <td>133.704110</td>\n",
       "      <td>16.421341</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>664.119937</td>\n",
       "      <td>6659.508551</td>\n",
       "      <td>441.417495</td>\n",
       "      <td>3515.709131</td>\n",
       "      <td>170.638574</td>\n",
       "      <td>983.308293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>TCGA-EW-A1IY-01</td>\n",
       "      <td>LumB</td>\n",
       "      <td>224.769115</td>\n",
       "      <td>2.975228</td>\n",
       "      <td>1.564390</td>\n",
       "      <td>3164.803036</td>\n",
       "      <td>4088.058143</td>\n",
       "      <td>1725.740707</td>\n",
       "      <td>7941.523033</td>\n",
       "      <td>8.054528</td>\n",
       "      <td>...</td>\n",
       "      <td>1.564390</td>\n",
       "      <td>2.693160</td>\n",
       "      <td>23.010174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>987.543166</td>\n",
       "      <td>3035.671573</td>\n",
       "      <td>254.125969</td>\n",
       "      <td>2333.856269</td>\n",
       "      <td>248.758153</td>\n",
       "      <td>1068.521336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>TCGA-BH-A1EV-11</td>\n",
       "      <td>Normal</td>\n",
       "      <td>677.839547</td>\n",
       "      <td>152.609398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2990.145558</td>\n",
       "      <td>3762.302148</td>\n",
       "      <td>2229.647612</td>\n",
       "      <td>7021.677400</td>\n",
       "      <td>32.258333</td>\n",
       "      <td>...</td>\n",
       "      <td>2.722817</td>\n",
       "      <td>51.453596</td>\n",
       "      <td>17.490505</td>\n",
       "      <td>1.246083</td>\n",
       "      <td>975.433696</td>\n",
       "      <td>8860.055373</td>\n",
       "      <td>417.693244</td>\n",
       "      <td>2007.382739</td>\n",
       "      <td>718.677147</td>\n",
       "      <td>808.778031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>TCGA-D8-A142-01</td>\n",
       "      <td>Basal</td>\n",
       "      <td>836.313476</td>\n",
       "      <td>3.124878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3792.149168</td>\n",
       "      <td>2191.647406</td>\n",
       "      <td>1012.425476</td>\n",
       "      <td>5846.672232</td>\n",
       "      <td>19.061635</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.124878</td>\n",
       "      <td>24.639482</td>\n",
       "      <td>4.452760</td>\n",
       "      <td>616.945825</td>\n",
       "      <td>8506.205536</td>\n",
       "      <td>530.864552</td>\n",
       "      <td>1932.429411</td>\n",
       "      <td>71.913962</td>\n",
       "      <td>1047.765392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>TCGA-BH-A1FC-01</td>\n",
       "      <td>Basal</td>\n",
       "      <td>815.985666</td>\n",
       "      <td>4.824903</td>\n",
       "      <td>1.588538</td>\n",
       "      <td>3225.484123</td>\n",
       "      <td>1031.694418</td>\n",
       "      <td>969.905245</td>\n",
       "      <td>5492.320120</td>\n",
       "      <td>12.474413</td>\n",
       "      <td>...</td>\n",
       "      <td>1.882696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.774711</td>\n",
       "      <td>3.059509</td>\n",
       "      <td>869.534826</td>\n",
       "      <td>1441.844634</td>\n",
       "      <td>130.165202</td>\n",
       "      <td>1874.902684</td>\n",
       "      <td>57.492426</td>\n",
       "      <td>1011.373383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964 rows Ã— 20532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              sample   Class   ARHGEF10L       HIF3A      RNF17        RNF10   \\\n",
       "0    TCGA-A8-A092-01    LumB   470.613860    1.294325   1.000000  4032.615110   \n",
       "1    TCGA-A7-A0CE-11  Normal  1022.581418   71.476644  18.142483  3556.148857   \n",
       "2    TCGA-D8-A1JK-01   Basal   499.866835    3.858928   1.952876  3154.728205   \n",
       "3    TCGA-BH-A0AY-11  Normal   871.888597  211.439338   1.000000  3402.784330   \n",
       "4    TCGA-E2-A10C-01    LumB   823.542903    1.475701   1.000000  3785.583565   \n",
       "..               ...     ...          ...         ...        ...          ...   \n",
       "959  TCGA-BH-A0BJ-01    LumA   756.292237    3.510557   1.000000  3534.278468   \n",
       "960  TCGA-EW-A1IY-01    LumB   224.769115    2.975228   1.564390  3164.803036   \n",
       "961  TCGA-BH-A1EV-11  Normal   677.839547  152.609398   1.000000  2990.145558   \n",
       "962  TCGA-D8-A142-01   Basal   836.313476    3.124878   1.000000  3792.149168   \n",
       "963  TCGA-BH-A1FC-01   Basal   815.985666    4.824903   1.588538  3225.484123   \n",
       "\n",
       "          RNF11        RNF13       GTF2IP1       REM1   ...    TULP2   \\\n",
       "0    1501.407625  1583.498736   4522.798478   3.354040  ...  1.000000   \n",
       "1    2387.690290  1341.284905   6638.768825  67.033019  ...  1.634897   \n",
       "2    3317.774228  1173.579614   3601.794112  15.294065  ...  1.476519   \n",
       "3    3406.560232  1826.163218   6768.404146  91.000338  ...  1.434751   \n",
       "4    1471.936787   604.710157  11215.450880   9.087604  ...  1.475701   \n",
       "..           ...          ...           ...        ...  ...       ...   \n",
       "959  2569.549982  1138.643179   8383.285226  23.954088  ...  1.717250   \n",
       "960  4088.058143  1725.740707   7941.523033   8.054528  ...  1.564390   \n",
       "961  3762.302148  2229.647612   7021.677400  32.258333  ...  2.722817   \n",
       "962  2191.647406  1012.425476   5846.672232  19.061635  ...  1.000000   \n",
       "963  1031.694418   969.905245   5492.320120  12.474413  ...  1.882696   \n",
       "\n",
       "         NPY5R      GNGT2     GNGT1       TULP3          PTRF       BCL6B   \\\n",
       "0      1.294325  15.124337  1.294325  665.733058   2922.120588  136.352751   \n",
       "1     16.872478  35.919615  1.317497  654.976802  14108.725020  259.735608   \n",
       "2      1.000000  37.689742  2.429400  584.192489   6826.829473  469.864187   \n",
       "3    101.871028  13.173803  1.000000  768.392699  23292.857250  789.721414   \n",
       "4      1.475701  17.174545  1.475701  524.791303   3105.263544  229.348872   \n",
       "..          ...        ...       ...         ...           ...         ...   \n",
       "959  133.704110  16.421341  1.000000  664.119937   6659.508551  441.417495   \n",
       "960    2.693160  23.010174  1.000000  987.543166   3035.671573  254.125969   \n",
       "961   51.453596  17.490505  1.246083  975.433696   8860.055373  417.693244   \n",
       "962    3.124878  24.639482  4.452760  616.945825   8506.205536  530.864552   \n",
       "963    1.000000  27.774711  3.059509  869.534826   1441.844634  130.165202   \n",
       "\n",
       "          GSTK1        SELP         SELS   \n",
       "0    1046.749127   15.124337   711.342228  \n",
       "1    3730.103638  694.966680  1163.213337  \n",
       "2    5993.986005   13.388292  1184.120347  \n",
       "3    2264.536378  645.333004   943.579327  \n",
       "4    2363.976535   27.165430   981.469755  \n",
       "..           ...         ...          ...  \n",
       "959  3515.709131  170.638574   983.308293  \n",
       "960  2333.856269  248.758153  1068.521336  \n",
       "961  2007.382739  718.677147   808.778031  \n",
       "962  1932.429411   71.913962  1047.765392  \n",
       "963  1874.902684   57.492426  1011.373383  \n",
       "\n",
       "[964 rows x 20532 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.803448275862069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.89      0.94      0.91        51\n",
      "        Her2       0.00      0.00      0.00        17\n",
      "        LumA       0.90      0.82      0.85       119\n",
      "        LumB       0.62      0.83      0.71        66\n",
      "      Normal       0.85      0.89      0.87        37\n",
      "\n",
      "    accuracy                           0.80       290\n",
      "   macro avg       0.65      0.70      0.67       290\n",
      "weighted avg       0.77      0.80      0.78       290\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmood\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries  \n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "data = pd.read_csv(\"C:/Users/Mahmood/Desktop/Final_DataSet/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/RNA-seq_BreastDataStructured1.csv\")\n",
    "data3=data.drop(['sample'], axis=1)\n",
    "# loading the iris dataset \n",
    "# X -> features, y -> label \n",
    "X = data3.drop('Class', axis=1)\n",
    "y =data3['Class']\n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =42) \n",
    "  \n",
    "# training a DescisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(X_test) \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, dtree_predictions) \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, dtree_predictions))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7862068965517242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.94      0.96      0.95        51\n",
      "        Her2       0.79      0.65      0.71        17\n",
      "        LumA       0.84      0.70      0.76       119\n",
      "        LumB       0.60      0.79      0.68        66\n",
      "      Normal       0.85      0.89      0.87        37\n",
      "\n",
      "    accuracy                           0.79       290\n",
      "   macro avg       0.80      0.80      0.80       290\n",
      "weighted avg       0.80      0.79      0.79       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries \n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "data = pd.read_csv(\"C:/Users/Mahmood/Desktop/Final_DataSet/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/RNA-seq_BreastDataStructured1.csv\")\n",
    "data3=data.drop(['sample'], axis=1)\n",
    "X3 = data3.drop('Class', axis=1)\n",
    "y3 =data3['Class']\n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.3,random_state = 42) \n",
    "  \n",
    "# training a Naive Bayes classifier \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB().fit(X_train3, y_train3) \n",
    "gnb_predictions = gnb.predict(X_test3) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = gnb.score(X_test3, y_test3) \n",
    "print (accuracy) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test3, gnb_predictions) \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test3, gnb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7172413793103448\n",
      "Accuracy: 0.7172413793103448\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.80      0.84      0.82        51\n",
      "        Her2       1.00      0.24      0.38        17\n",
      "        LumA       0.66      0.89      0.76       119\n",
      "        LumB       0.71      0.36      0.48        66\n",
      "      Normal       0.84      0.84      0.84        37\n",
      "\n",
      "    accuracy                           0.72       290\n",
      "   macro avg       0.80      0.63      0.65       290\n",
      "weighted avg       0.74      0.72      0.69       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries \n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "data = pd.read_csv(\"C:/Users/Mahmood/Desktop/Final_DataSet/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/RNA-seq_BreastDataStructured1.csv\")\n",
    "data3=data.drop(['sample'], axis=1)\n",
    "# X -> features, y -> label \n",
    "X2 = data3.drop('Class', axis=1)\n",
    "y2 =data3['Class']\n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2,test_size=0.3, random_state = 42) \n",
    "  \n",
    "# training a KNN classifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train2, y_train2) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = knn.score(X_test2, y_test2) \n",
    "print (accuracy) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "knn_predictions = knn.predict(X_test2)  \n",
    "cm = confusion_matrix(y_test2, knn_predictions) \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, knn_predictions))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test2, knn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.91      0.96      0.93        51\n",
      "        Her2       0.60      0.71      0.65        17\n",
      "        LumA       0.81      0.81      0.81       119\n",
      "        LumB       0.69      0.64      0.66        66\n",
      "      Normal       0.92      0.89      0.90        37\n",
      "\n",
      "    accuracy                           0.80       290\n",
      "   macro avg       0.78      0.80      0.79       290\n",
      "weighted avg       0.80      0.80      0.80       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries \n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "data = pd.read_csv(\"C:/Users/Mahmood/Desktop/Final_DataSet/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/RNA-seq_BreastDataStructured1.csv\")\n",
    "data3=data.drop(['sample'], axis=1)\n",
    "# X -> features, y -> label \n",
    "X1 = data3.drop('Class', axis=1)\n",
    "y1 =data3['Class']\n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1,test_size=0.3, random_state = 42) \n",
    "  \n",
    "# training a linear SVM classifier \n",
    "from sklearn.svm import SVC \n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train1, y_train1) \n",
    "svm_predictions = svm_model_linear.predict(X_test1) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(X_test1, y_test1) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test1, svm_predictions) \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test1, svm_predictions))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test1, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.803448275862069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.94      0.96      0.95        51\n",
      "        Her2       0.36      0.53      0.43        17\n",
      "        LumA       0.90      0.80      0.84       119\n",
      "        LumB       0.71      0.70      0.70        66\n",
      "      Normal       0.81      0.92      0.86        37\n",
      "\n",
      "    accuracy                           0.80       290\n",
      "   macro avg       0.74      0.78      0.76       290\n",
      "weighted avg       0.82      0.80      0.81       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries \n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "data2 = pd.read_csv(\"C:/Users/Mahmood/Desktop/Camparsion/BreastCancer/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/geneselected/Structure_Combine.csv\")  \n",
    "X3 = data2.drop('Class', axis=1)\n",
    "y3 =data2['Class']\n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.3,random_state = 42) \n",
    "  \n",
    "# training a Naive Bayes classifier \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB().fit(X_train3, y_train3) \n",
    "gnb_predictions = gnb.predict(X_test3) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = gnb.score(X_test3, y_test3) \n",
    "print (accuracy) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test3, gnb_predictions) \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test3, gnb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.803448275862069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.89      0.94      0.91        51\n",
      "        Her2       0.00      0.00      0.00        17\n",
      "        LumA       0.90      0.82      0.85       119\n",
      "        LumB       0.62      0.83      0.71        66\n",
      "      Normal       0.85      0.89      0.87        37\n",
      "\n",
      "    accuracy                           0.80       290\n",
      "   macro avg       0.65      0.70      0.67       290\n",
      "weighted avg       0.77      0.80      0.78       290\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmood\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd\n",
    "data2 = pd.read_csv(\"C:/Users/Mahmood/Desktop/Camparsion/BreastCancer/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/geneselected/Structure_Combine.csv\")  \n",
    "X = data2.drop('Class', axis=1)\n",
    "y=data2['Class']\n",
    "# dividing X, y into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42) \n",
    "  \n",
    "# training a DescisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(X_test) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, dtree_predictions) \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, dtree_predictions))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8482758620689655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.94      0.98      0.96        51\n",
      "        Her2       0.53      0.53      0.53        17\n",
      "        LumA       0.88      0.87      0.87       119\n",
      "        LumB       0.76      0.77      0.77        66\n",
      "      Normal       0.92      0.89      0.90        37\n",
      "\n",
      "    accuracy                           0.85       290\n",
      "   macro avg       0.81      0.81      0.81       290\n",
      "weighted avg       0.85      0.85      0.85       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries \n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd\n",
    "data2 = pd.read_csv(\"C:/Users/Mahmood/Desktop/Camparsion/BreastCancer/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/geneselected/Structure_Combine.csv\")  \n",
    "X1 = data2.drop('Class', axis=1)\n",
    "y1 =data2['Class']\n",
    "\n",
    "# dividing X, y into train and test data \n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1,test_size=0.3, random_state = 42) \n",
    "  \n",
    "# training a linear SVM classifier \n",
    "from sklearn.svm import SVC \n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train1, y_train1) \n",
    "svm_predictions = svm_model_linear.predict(X_test1) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(X_test1, y_test1) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test1, svm_predictions) \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test1, svm_predictions))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test1, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8137931034482758\n",
      "Accuracy: 0.8137931034482758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.98      0.96      0.97        51\n",
      "        Her2       0.65      0.65      0.65        17\n",
      "        LumA       0.77      0.89      0.83       119\n",
      "        LumB       0.72      0.55      0.62        66\n",
      "      Normal       0.94      0.92      0.93        37\n",
      "\n",
      "    accuracy                           0.81       290\n",
      "   macro avg       0.81      0.79      0.80       290\n",
      "weighted avg       0.81      0.81      0.81       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries \n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd\n",
    "data2 = pd.read_csv(\"C:/Users/Mahmood/Desktop/Camparsion/BreastCancer/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/geneselected/Structure_Combine.csv\")  \n",
    "X2 = data2.drop('Class', axis=1)\n",
    "y2 =data2['Class']\n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2,test_size=0.3, random_state = 42) \n",
    "  \n",
    "# training a KNN classifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train2, y_train2) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = knn.score(X_test2, y_test2) \n",
    "print (accuracy) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "knn_predictions = knn.predict(X_test2)  \n",
    "cm = confusion_matrix(y_test2, knn_predictions) \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, knn_predictions))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test2 ,knn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.803448275862069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.89      0.94      0.91        51\n",
      "        Her2       0.00      0.00      0.00        17\n",
      "        LumA       0.90      0.82      0.85       119\n",
      "        LumB       0.62      0.83      0.71        66\n",
      "      Normal       0.85      0.89      0.87        37\n",
      "\n",
      "    accuracy                           0.80       290\n",
      "   macro avg       0.65      0.70      0.67       290\n",
      "weighted avg       0.77      0.80      0.78       290\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmood\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd\n",
    "data2 = pd.read_csv(\"C:/Users/Mahmood/Desktop/Camparsion/BreastCancer/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/geneselected/TOP_50/combine_ml.csv\")  \n",
    "X = data2.drop('Class', axis=1)\n",
    "y=data2['Class']\n",
    "# dividing X, y into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42) \n",
    "  \n",
    "# training a DescisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(X_test) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, dtree_predictions) \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, dtree_predictions))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8551724137931035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.96      0.98        51\n",
      "        Her2       0.61      0.82      0.70        17\n",
      "        LumA       0.87      0.86      0.86       119\n",
      "        LumB       0.75      0.73      0.74        66\n",
      "      Normal       0.95      0.95      0.95        37\n",
      "\n",
      "    accuracy                           0.86       290\n",
      "   macro avg       0.84      0.86      0.85       290\n",
      "weighted avg       0.86      0.86      0.86       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd\n",
    "data2 = pd.read_csv(\"C:/Users/Mahmood/Desktop/Camparsion/BreastCancer/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/geneselected/TOP_50/combine_ml.csv\")  \n",
    "X1 = data2.drop('Class', axis=1)\n",
    "y1 =data2['Class']\n",
    "\n",
    "# dividing X, y into train and test data \n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1,test_size=0.3, random_state =42) \n",
    "  \n",
    "# training a linear SVM classifier \n",
    "from sklearn.svm import SVC \n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train1, y_train1) \n",
    "svm_predictions = svm_model_linear.predict(X_test1) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(X_test1, y_test1) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test1, svm_predictions) \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test1, svm_predictions))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test1, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7482758620689656\n",
      "Accuracy: 0.7482758620689656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.96      1.00      0.98        51\n",
      "        Her2       0.67      0.47      0.55        17\n",
      "        LumA       0.65      0.91      0.76       119\n",
      "        LumB       0.65      0.23      0.34        66\n",
      "      Normal       0.97      0.95      0.96        37\n",
      "\n",
      "    accuracy                           0.75       290\n",
      "   macro avg       0.78      0.71      0.72       290\n",
      "weighted avg       0.75      0.75      0.71       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries \n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd\n",
    "data2 = pd.read_csv(\"C:/Users/Mahmood/Desktop/Camparsion/BreastCancer/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/geneselected/TOP_50/combine_ml.csv\")\n",
    "X2 = data2.drop('Class', axis=1)\n",
    "y2 =data2['Class']\n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2,test_size=0.3, random_state = 42) \n",
    "  \n",
    "# training a KNN classifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train2, y_train2) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = knn.score(X_test2, y_test2) \n",
    "print (accuracy) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "knn_predictions = knn.predict(X_test2)  \n",
    "cm = confusion_matrix(y_test2, knn_predictions) \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, knn_predictions))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test2 ,knn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8413793103448276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.92      0.94      0.93        51\n",
      "        Her2       0.55      0.71      0.62        17\n",
      "        LumA       0.93      0.83      0.88       119\n",
      "        LumB       0.72      0.77      0.74        66\n",
      "      Normal       0.89      0.92      0.91        37\n",
      "\n",
      "    accuracy                           0.84       290\n",
      "   macro avg       0.80      0.83      0.81       290\n",
      "weighted avg       0.85      0.84      0.84       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries \n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "data2 = pd.read_csv(\"C:/Users/Mahmood/Desktop/Camparsion/BreastCancer/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/geneselected/TOP_50/combine_ml.csv\")  \n",
    "X3 = data2.drop('Class', axis=1)\n",
    "y3 =data2['Class']\n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.3,random_state = 42) \n",
    "  \n",
    "# training a Naive Bayes classifier \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB().fit(X_train3, y_train3) \n",
    "gnb_predictions = gnb.predict(X_test3) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = gnb.score(X_test3, y_test3) \n",
    "print (accuracy) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test3, gnb_predictions) \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test3, gnb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?///////////////////////////// FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported featurewiz: advanced feature engg and selection library. Version=0.0.42\n",
      "output = featurewiz(dataname, target, corr_limit=0.70,\n",
      "                    verbose=2, sep=',', header=0, test_data='',\n",
      "                    feature_engg='', category_encoders='')\n",
      "Create new features via 'feature_engg' flag : ['interactions','groupby','target']\n",
      "                                \n",
      "Skipping feature engineering since no feature_engg input...\n",
      "Skipping category encoding since no category encoders specified in input...\n",
      "Loading train data...\n",
      "Shape of your Data Set loaded: (964, 20531)\n",
      "Loading test data...\n",
      "    Filename is an empty string or file not able to be loaded\n",
      "############## C L A S S I F Y I N G  V A R I A B L E S  ####################\n",
      "Classifying variables in data set...\n",
      "    20530 Predictors classified...\n",
      "        289 variable(s) will be ignored since they are ID or low-information variables\n",
      "No GPU active on this device\n",
      "    Running XGBoost using CPU parameters\n",
      "Removing 289 columns from further processing since ID or low information variables\n",
      "    columns removed: ['RBMY1A3P ', 'SNORD115-17 ', 'SNORD114-31 ', 'SNORD114-30 ', 'SNORD115-6 ', 'SNORD115-4 ', 'SNORD104 ', 'SNORD115-9 ', 'SNORD38A ', 'KRTAP19-7 ', 'KRTAP19-4 ', 'SNORD114-3 ', 'HBII-52-27 ', 'SNORD11 ', 'SNORD12 ', 'SNORD21 ', 'SNORD20 ', 'SNORD25 ', 'SNORD127 ', 'DAZ3 ', 'DAZ2 ', 'DAZ4 ', 'SNORD124 ', 'TTTY17A ', 'SNORD115-5 ', 'SNORD80 ', 'SNORD56B ', 'SNORD78 ', 'SNORD113-7 ', 'SNORD96A ', 'SNORD119 ', 'HBII-52-46 ', 'HBII-52-45 ', 'SNORD47 ', 'SNORD4B ', 'SNORD4A ', 'SNORD116-24 ', 'SNORD116-25 ', 'SNORD116-23 ', 'SNORD116-29 ', 'RBMY1B ', 'RBMY1F ', 'BPY2 ', 'SNORD115-8 ', 'SNORD66 ', 'HBII-52-28 ', 'SNORD69 ', 'SNORD68 ', 'SNORD38B ', 'SNORD113-4 ', 'SNORD116-26 ', 'SNORD115-1 ', 'SNORD58A ', 'SNORD58C ', 'PRR20A ', 'PRR20D ', 'SNORD96B ', 'SNORD63 ', 'SNORD116-22 ', 'SNORD81 ', 'PLA2G2E ', 'PRAMEF3 ', 'SNORD114-20 ', 'SNAR-A3 ', 'SNORD115-20 ', 'SNORD115-22 ', 'SNORD115-25 ', 'SNORD114-29 ', 'TEX28 ', 'CEACAM18 ', 'SNORD29 ', 'S100A7L2 ', 'LOC653545 ', 'SNORD16 ', 'SNORD36A ', 'SNORD91B ', 'SNORD87 ', 'SNORD86 ', 'DEFB116 ', 'DEFB114 ', 'DEFB112 ', 'TTTY4C ', 'RBMY1E ', 'SNORD91A ', 'SNORD88B ', 'SNORD50B ', 'SNORD65 ', 'KRTAP22-1 ', 'SNORD61 ', 'SNORD115-35 ', 'SNORD114-10 ', 'SNORD114-6 ', 'SNORD114-5 ', 'SNORD12C ', 'SNORD123 ', 'SNORD126 ', 'SNORD125 ', 'KRTAP23-1 ', 'SNORD48 ', 'SNORD114-9 ', 'SNORD46 ', 'SNORD115-2 ', 'SNORD115-3 ', 'SNORD27 ', 'SNORD105 ', 'RBMY2EP ', 'SNORD35A ', 'SNORD35B ', 'RBMY3AP ', 'TTTY22 ', 'SNORD24 ', 'SNORD28 ', 'TTTY6B ', 'SNORD49A ', 'SNORD102 ', 'SNORD115-14 ', 'SNORD115-16 ', 'SNORD30 ', 'SNORD31 ', 'SNORD115-10 ', 'SNORD18B ', 'SNORD26 ', 'SNORD114-7 ', 'SNORD45C ', 'SNORD111B ', 'SNORD18A ', 'TTTY6 ', 'TTTY7 ', 'TTTY5 ', 'TTTY20 ', 'CT47A9 ', 'SNORD109B ', 'SNORD45B ', 'SNORD45A ', 'SNORD114-22 ', 'SNORD114-23 ', 'SNORD114-26 ', 'SNORD114-27 ', 'SNORD114-24 ', 'SNORD114-25 ', 'SNORD114-28 ', 'SNORD115-41 ', 'SNORD115-40 ', 'SNORD1A ', 'SNORD1B ', 'SNORD19 ', 'SNORD115-37 ', 'SNORD44 ', 'SNORD34 ', 'SNORD121B ', 'SNORD121A ', 'SNAR-H ', 'SNORD51 ', 'SNORD115-44 ', 'SNORD36C ', 'SNORD115-48 ', 'SNORD11B ', 'SNORD49B ', 'SNORA35 ', 'SNORD116-11 ', '?|136542 ', 'SNORD59B ', 'SNORD59A ', 'SNORD116-27 ', 'SNORD114-21 ', 'SNORD114-11 ', 'SNORD72 ', 'SNORD74 ', 'SNORD75 ', 'SNORD79 ', 'SNORD114-4 ', 'CDY1 ', 'RNU5E ', 'SNORD88C ', 'RNY5 ', 'RNY4 ', 'SNORD114-16 ', 'SNORD52 ', 'SNORD53 ', 'SNORD115-11 ', 'SNORD113-9 ', 'SNORD113-5 ', 'SNORD113-6 ', 'SNORD113-1 ', 'SNORD113-2 ', 'SNORD114-14 ', 'SNORD116-18 ', 'KRTAP20-3 ', 'SNORD98 ', 'SNORD99 ', 'SNORD93 ', 'KRTAP20-1 ', 'SNORD116-12 ', 'SNORD73A ', 'SNORD115-32 ', 'SNORD115-39 ', 'SNAR-D ', 'DEFB122 ', 'SNORD116-10 ', 'SNORD116-13 ', 'SNORD116-15 ', 'SNORD116-14 ', 'SNORD116-16 ', 'XKRY ', 'SNORD95 ', 'SNORD90 ', 'SNORD114-18 ', 'SNORD92 ', 'TSSK2 ', 'SNORA70C ', 'SNORD114-15 ', 'SNORD19B ', 'SNORD70 ', 'SNORD76 ', 'SNORD77 ', 'HBII-52-24 ', 'SNORD60 ', 'TXNDC8 ', 'TTTY3B ', 'KRTAP13-3 ', 'SNORA11C ', 'SNORD105B ', 'TTTY17B ', 'SNORD6 ', 'SNORD7 ', 'SNORD5 ', 'SNORD2 ', 'SNORD9 ', 'SNORD33 ', 'VTRNA1-2 ', 'SNAR-G2 ', 'SNORD54 ', 'TTTY16 ', 'TTTY18 ', 'TTTY1B ', 'FAM197Y2 ', 'SNORD114-8 ', 'SNORD55 ', 'SNORD56 ', 'SNORD57 ', 'DUX4 ', 'SNORD50A ', 'SNORD117 ', 'SNORD110 ', 'SNORD111 ', 'SNAR-A4 ', 'TTTY12 ', 'SNORD32A ', 'SNORD43 ', 'SNORD114-12 ', 'SNORD71 ', 'PRR20B ', 'SNAR-C3 ', 'SNAR-C2 ', 'SNORD88A ', 'SNORD36B ', 'VTRNA1-3 ', 'VTRNA1-1 ', 'SNORD41 ', 'SNORD62A ', 'LCE3B ', 'SNORD116-5 ', 'SNORD42B ', 'SNORD42A ', 'SNORD37 ', 'SNORD114-1 ', 'TTTY11 ', 'TTTY13 ', 'TTTY19 ', 'SNORD115-33 ', 'SNORD115-30 ', 'SNORD115-31 ', 'SNORD114-2 ', 'SNORD115-38 ', 'SNORD18C ', 'SNORD12B ', 'CDY2B ', 'SNORD114-19 ', 'SNORD114-13 ', 'SNORD114-17 ', 'CT47A10 ', 'SNORD116-8 ', 'SNORD116-1 ', 'SNORD116-3 ', 'SNORD116-2 ', 'SNORD85 ', 'SNORD84 ', 'SNORD82 ', 'SNORD32B ']\n",
      "    After removing redundant variables from further processing, features left = 20241\n",
      "#### Single_Label Multi_Classification Feature Selection Started ####\n",
      "Searching for highly correlated variables from 20241 variables using SULOV method\n",
      "#####  SULOV : Searching for Uncorrelated List Of Variables (takes time...) ############\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# import packages \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from featurewiz import featurewiz\n",
    "import pandas as pd\n",
    "data3 = pd.read_csv(\"C:/Users/Mahmood/Desktop/Final_DataSet/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/RNA-seq_BreastDataStructured1.csv\")\n",
    "np.random.seed(1234)\n",
    "data3=data3.drop(['sample'], axis=1)\n",
    "X = data3.drop('Class', axis=1)\n",
    "y =data3['Class']\n",
    "X = X.astype('float32')\n",
    "# encode strings to integer\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "X_scaled =  StandardScaler().fit_transform(X)\n",
    "target = 'Class'\n",
    "features, train = featurewiz(data3, target, corr_limit=0.7, verbose=2, sep=\",\",\n",
    "header=0,test_data=\"\", feature_engg=\"\", category_encoders=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7935ff3c6b97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata4\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Class'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data3' is not defined"
     ]
    }
   ],
   "source": [
    "data4=data3[features]\n",
    "data4['Class'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PHYHIP</th>\n",
       "      <th>PSAT1</th>\n",
       "      <th>MATN2</th>\n",
       "      <th>MAMDC2</th>\n",
       "      <th>TBC1D9</th>\n",
       "      <th>C20orf103</th>\n",
       "      <th>SLC7A8</th>\n",
       "      <th>SOBP</th>\n",
       "      <th>CA12</th>\n",
       "      <th>DMD</th>\n",
       "      <th>...</th>\n",
       "      <th>ELF5</th>\n",
       "      <th>FGF7</th>\n",
       "      <th>ZNF780A</th>\n",
       "      <th>ZNF628</th>\n",
       "      <th>SPDYE6</th>\n",
       "      <th>C3orf63</th>\n",
       "      <th>RNF169</th>\n",
       "      <th>GOLGA8C</th>\n",
       "      <th>USP32</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.942471</td>\n",
       "      <td>566.251831</td>\n",
       "      <td>4479.431714</td>\n",
       "      <td>55.986225</td>\n",
       "      <td>3269.603551</td>\n",
       "      <td>145.482317</td>\n",
       "      <td>1789.201305</td>\n",
       "      <td>28.954185</td>\n",
       "      <td>6517.034875</td>\n",
       "      <td>51.318248</td>\n",
       "      <td>...</td>\n",
       "      <td>145.482317</td>\n",
       "      <td>40.431281</td>\n",
       "      <td>533.298700</td>\n",
       "      <td>140.477961</td>\n",
       "      <td>46.607816</td>\n",
       "      <td>2189.521650</td>\n",
       "      <td>745.414979</td>\n",
       "      <td>1.294325</td>\n",
       "      <td>1636.162131</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316.245250</td>\n",
       "      <td>200.686533</td>\n",
       "      <td>4150.012596</td>\n",
       "      <td>1115.442167</td>\n",
       "      <td>6553.727625</td>\n",
       "      <td>78.776860</td>\n",
       "      <td>2218.086634</td>\n",
       "      <td>281.950873</td>\n",
       "      <td>6662.278739</td>\n",
       "      <td>1162.246205</td>\n",
       "      <td>...</td>\n",
       "      <td>1240.666805</td>\n",
       "      <td>786.716483</td>\n",
       "      <td>297.511165</td>\n",
       "      <td>130.526597</td>\n",
       "      <td>24.174263</td>\n",
       "      <td>1437.453927</td>\n",
       "      <td>379.669422</td>\n",
       "      <td>15.285586</td>\n",
       "      <td>975.636553</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.723443</td>\n",
       "      <td>753.832403</td>\n",
       "      <td>1038.294507</td>\n",
       "      <td>4.811878</td>\n",
       "      <td>2275.235240</td>\n",
       "      <td>53.888294</td>\n",
       "      <td>1054.980049</td>\n",
       "      <td>43.405321</td>\n",
       "      <td>1245.060386</td>\n",
       "      <td>455.087453</td>\n",
       "      <td>...</td>\n",
       "      <td>3.858928</td>\n",
       "      <td>100.580024</td>\n",
       "      <td>155.373860</td>\n",
       "      <td>119.163616</td>\n",
       "      <td>16.723443</td>\n",
       "      <td>1183.053827</td>\n",
       "      <td>358.095356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1166.928135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>163.608058</td>\n",
       "      <td>230.560251</td>\n",
       "      <td>4355.733585</td>\n",
       "      <td>1049.946426</td>\n",
       "      <td>6623.141658</td>\n",
       "      <td>16.217730</td>\n",
       "      <td>1277.493292</td>\n",
       "      <td>302.313166</td>\n",
       "      <td>4791.295240</td>\n",
       "      <td>1389.259124</td>\n",
       "      <td>...</td>\n",
       "      <td>970.106952</td>\n",
       "      <td>835.791919</td>\n",
       "      <td>284.483270</td>\n",
       "      <td>89.697757</td>\n",
       "      <td>31.000079</td>\n",
       "      <td>1878.545052</td>\n",
       "      <td>906.711643</td>\n",
       "      <td>1.869562</td>\n",
       "      <td>995.377524</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.942227</td>\n",
       "      <td>232.679452</td>\n",
       "      <td>1055.711558</td>\n",
       "      <td>8.683039</td>\n",
       "      <td>3488.037898</td>\n",
       "      <td>71.884061</td>\n",
       "      <td>4061.790178</td>\n",
       "      <td>61.418442</td>\n",
       "      <td>4766.451826</td>\n",
       "      <td>67.602280</td>\n",
       "      <td>...</td>\n",
       "      <td>705.107786</td>\n",
       "      <td>174.647236</td>\n",
       "      <td>260.276275</td>\n",
       "      <td>130.399995</td>\n",
       "      <td>30.020997</td>\n",
       "      <td>1056.443576</td>\n",
       "      <td>120.083989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>671.805595</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>21.442482</td>\n",
       "      <td>35.787900</td>\n",
       "      <td>434.616760</td>\n",
       "      <td>95.233682</td>\n",
       "      <td>8035.098532</td>\n",
       "      <td>871.465656</td>\n",
       "      <td>1468.268398</td>\n",
       "      <td>79.904231</td>\n",
       "      <td>11213.896200</td>\n",
       "      <td>205.073889</td>\n",
       "      <td>...</td>\n",
       "      <td>822.288020</td>\n",
       "      <td>196.107378</td>\n",
       "      <td>450.037060</td>\n",
       "      <td>164.187445</td>\n",
       "      <td>15.704434</td>\n",
       "      <td>1737.503297</td>\n",
       "      <td>975.433696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1376.033616</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>16.237977</td>\n",
       "      <td>232.679452</td>\n",
       "      <td>361.913221</td>\n",
       "      <td>248.999666</td>\n",
       "      <td>12219.520040</td>\n",
       "      <td>314.213205</td>\n",
       "      <td>6256.326112</td>\n",
       "      <td>80.856957</td>\n",
       "      <td>8510.923686</td>\n",
       "      <td>297.573037</td>\n",
       "      <td>...</td>\n",
       "      <td>506.669087</td>\n",
       "      <td>239.154645</td>\n",
       "      <td>444.888501</td>\n",
       "      <td>42.197921</td>\n",
       "      <td>27.525560</td>\n",
       "      <td>2886.488976</td>\n",
       "      <td>742.733067</td>\n",
       "      <td>5.232861</td>\n",
       "      <td>1259.556392</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>104.372657</td>\n",
       "      <td>254.760889</td>\n",
       "      <td>3719.260284</td>\n",
       "      <td>1202.315660</td>\n",
       "      <td>4558.678653</td>\n",
       "      <td>21.674097</td>\n",
       "      <td>1137.617620</td>\n",
       "      <td>186.327912</td>\n",
       "      <td>2690.204257</td>\n",
       "      <td>2471.892007</td>\n",
       "      <td>...</td>\n",
       "      <td>1578.457827</td>\n",
       "      <td>1208.498528</td>\n",
       "      <td>377.334447</td>\n",
       "      <td>42.347356</td>\n",
       "      <td>35.949505</td>\n",
       "      <td>2983.313758</td>\n",
       "      <td>920.516646</td>\n",
       "      <td>37.181163</td>\n",
       "      <td>1483.922467</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>28.622941</td>\n",
       "      <td>1351.831854</td>\n",
       "      <td>119.992465</td>\n",
       "      <td>200.464088</td>\n",
       "      <td>934.337525</td>\n",
       "      <td>349.997304</td>\n",
       "      <td>284.128551</td>\n",
       "      <td>69.526931</td>\n",
       "      <td>300.079302</td>\n",
       "      <td>414.003743</td>\n",
       "      <td>...</td>\n",
       "      <td>6221.298441</td>\n",
       "      <td>292.359569</td>\n",
       "      <td>259.699603</td>\n",
       "      <td>148.148478</td>\n",
       "      <td>19.061635</td>\n",
       "      <td>1372.984859</td>\n",
       "      <td>839.915278</td>\n",
       "      <td>2.859177</td>\n",
       "      <td>1149.746428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>3.059509</td>\n",
       "      <td>4011.983619</td>\n",
       "      <td>60.434481</td>\n",
       "      <td>256.248544</td>\n",
       "      <td>1029.337231</td>\n",
       "      <td>80.148299</td>\n",
       "      <td>298.461286</td>\n",
       "      <td>15.417533</td>\n",
       "      <td>218.138408</td>\n",
       "      <td>366.711068</td>\n",
       "      <td>...</td>\n",
       "      <td>1114.669269</td>\n",
       "      <td>100.740501</td>\n",
       "      <td>154.289920</td>\n",
       "      <td>114.277693</td>\n",
       "      <td>19.829824</td>\n",
       "      <td>1912.309074</td>\n",
       "      <td>928.655697</td>\n",
       "      <td>1.294235</td>\n",
       "      <td>1262.615805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964 rows Ã— 5424 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PHYHIP        PSAT1        MATN2       MAMDC2        TBC1D9   \\\n",
       "0      3.942471   566.251831  4479.431714    55.986225   3269.603551   \n",
       "1    316.245250   200.686533  4150.012596  1115.442167   6553.727625   \n",
       "2     16.723443   753.832403  1038.294507     4.811878   2275.235240   \n",
       "3    163.608058   230.560251  4355.733585  1049.946426   6623.141658   \n",
       "4     11.942227   232.679452  1055.711558     8.683039   3488.037898   \n",
       "..          ...          ...          ...          ...           ...   \n",
       "959   21.442482    35.787900   434.616760    95.233682   8035.098532   \n",
       "960   16.237977   232.679452   361.913221   248.999666  12219.520040   \n",
       "961  104.372657   254.760889  3719.260284  1202.315660   4558.678653   \n",
       "962   28.622941  1351.831854   119.992465   200.464088    934.337525   \n",
       "963    3.059509  4011.983619    60.434481   256.248544   1029.337231   \n",
       "\n",
       "     C20orf103       SLC7A8        SOBP          CA12          DMD   ...  \\\n",
       "0    145.482317  1789.201305   28.954185   6517.034875    51.318248  ...   \n",
       "1     78.776860  2218.086634  281.950873   6662.278739  1162.246205  ...   \n",
       "2     53.888294  1054.980049   43.405321   1245.060386   455.087453  ...   \n",
       "3     16.217730  1277.493292  302.313166   4791.295240  1389.259124  ...   \n",
       "4     71.884061  4061.790178   61.418442   4766.451826    67.602280  ...   \n",
       "..          ...          ...         ...           ...          ...  ...   \n",
       "959  871.465656  1468.268398   79.904231  11213.896200   205.073889  ...   \n",
       "960  314.213205  6256.326112   80.856957   8510.923686   297.573037  ...   \n",
       "961   21.674097  1137.617620  186.327912   2690.204257  2471.892007  ...   \n",
       "962  349.997304   284.128551   69.526931    300.079302   414.003743  ...   \n",
       "963   80.148299   298.461286   15.417533    218.138408   366.711068  ...   \n",
       "\n",
       "           ELF5         FGF7     ZNF780A      ZNF628     SPDYE6      C3orf63   \\\n",
       "0     145.482317    40.431281  533.298700  140.477961  46.607816  2189.521650   \n",
       "1    1240.666805   786.716483  297.511165  130.526597  24.174263  1437.453927   \n",
       "2       3.858928   100.580024  155.373860  119.163616  16.723443  1183.053827   \n",
       "3     970.106952   835.791919  284.483270   89.697757  31.000079  1878.545052   \n",
       "4     705.107786   174.647236  260.276275  130.399995  30.020997  1056.443576   \n",
       "..           ...          ...         ...         ...        ...          ...   \n",
       "959   822.288020   196.107378  450.037060  164.187445  15.704434  1737.503297   \n",
       "960   506.669087   239.154645  444.888501   42.197921  27.525560  2886.488976   \n",
       "961  1578.457827  1208.498528  377.334447   42.347356  35.949505  2983.313758   \n",
       "962  6221.298441   292.359569  259.699603  148.148478  19.061635  1372.984859   \n",
       "963  1114.669269   100.740501  154.289920  114.277693  19.829824  1912.309074   \n",
       "\n",
       "        RNF169    GOLGA8C        USP32   Class  \n",
       "0    745.414979   1.294325  1636.162131      3  \n",
       "1    379.669422  15.285586   975.636553      4  \n",
       "2    358.095356   1.000000  1166.928135      0  \n",
       "3    906.711643   1.869562   995.377524      4  \n",
       "4    120.083989   1.000000   671.805595      3  \n",
       "..          ...        ...          ...    ...  \n",
       "959  975.433696   1.000000  1376.033616      2  \n",
       "960  742.733067   5.232861  1259.556392      3  \n",
       "961  920.516646  37.181163  1483.922467      4  \n",
       "962  839.915278   2.859177  1149.746428      0  \n",
       "963  928.655697   1.294235  1262.615805      0  \n",
       "\n",
       "[964 rows x 5424 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7862068965517242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94        51\n",
      "           1       0.00      0.00      0.00        17\n",
      "           2       0.89      0.76      0.82       119\n",
      "           3       0.56      0.82      0.67        66\n",
      "           4       0.89      0.92      0.91        37\n",
      "\n",
      "    accuracy                           0.79       290\n",
      "   macro avg       0.65      0.69      0.67       290\n",
      "weighted avg       0.77      0.79      0.77       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "# loading the iris dataset \n",
    "# X -> features, y -> label \n",
    "X = data4.drop('Class', axis=1)\n",
    "y =data4['Class']\n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =42) \n",
    "  \n",
    "# training a DescisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(X_test) \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, dtree_predictions) \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, dtree_predictions))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8379310344827586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        51\n",
      "           1       0.79      0.65      0.71        17\n",
      "           2       0.84      0.82      0.83       119\n",
      "           3       0.72      0.79      0.75        66\n",
      "           4       0.92      0.89      0.90        37\n",
      "\n",
      "    accuracy                           0.84       290\n",
      "   macro avg       0.84      0.82      0.83       290\n",
      "weighted avg       0.84      0.84      0.84       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries \n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "X3 = data4.drop('Class', axis=1)\n",
    "y3 =data4['Class']\n",
    "\n",
    "# dividing X, y into train and test data \n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.3,random_state = 42) \n",
    "  \n",
    "# training a Naive Bayes classifier \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB().fit(X_train3, y_train3) \n",
    "gnb_predictions = gnb.predict(X_test3) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = gnb.score(X_test3, y_test3) \n",
    "print (accuracy) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test3, gnb_predictions) \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test3, gnb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7068965517241379\n",
      "Accuracy: 0.7068965517241379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86        51\n",
      "           1       0.56      0.29      0.38        17\n",
      "           2       0.68      0.91      0.77       119\n",
      "           3       0.57      0.20      0.29        66\n",
      "           4       0.77      0.92      0.84        37\n",
      "\n",
      "    accuracy                           0.71       290\n",
      "   macro avg       0.68      0.64      0.63       290\n",
      "weighted avg       0.68      0.71      0.66       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries \n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd\n",
    "X2 = data4.drop('Class', axis=1)\n",
    "y2 =data4['Class']\n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2,test_size=0.3, random_state = 42) \n",
    "  \n",
    "# training a KNN classifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train2, y_train2) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = knn.score(X_test2, y_test2) \n",
    "print (accuracy) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "knn_predictions = knn.predict(X_test2)  \n",
    "cm = confusion_matrix(y_test2, knn_predictions) \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, knn_predictions))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test2 ,knn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8517241379310345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        51\n",
      "           1       0.74      0.82      0.78        17\n",
      "           2       0.87      0.87      0.87       119\n",
      "           3       0.77      0.73      0.75        66\n",
      "           4       0.87      0.89      0.88        37\n",
      "\n",
      "    accuracy                           0.85       290\n",
      "   macro avg       0.84      0.85      0.84       290\n",
      "weighted avg       0.85      0.85      0.85       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd\n",
    "data2 = pd.read_csv(\"C:/Users/Mahmood/Desktop/Camparsion/BreastCancer/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/geneselected/TOP_50/combine_ml.csv\")  \n",
    "X1 = data4.drop('Class', axis=1)\n",
    "y1 =data4['Class']\n",
    "\n",
    "# dividing X, y into train and test data \n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1,test_size=0.3, random_state =42) \n",
    "  \n",
    "# training a linear SVM classifier \n",
    "from sklearn.svm import SVC \n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train1, y_train1) \n",
    "svm_predictions = svm_model_linear.predict(X_test1) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(X_test1, y_test1) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test1, svm_predictions) \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test1, svm_predictions))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test1, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.994065\n",
      "Test set score: 0.851724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        51\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.80      0.90      0.85       119\n",
      "           3       0.80      0.65      0.72        66\n",
      "           4       0.97      0.86      0.91        37\n",
      "\n",
      "    accuracy                           0.85       290\n",
      "   macro avg       0.88      0.86      0.86       290\n",
      "weighted avg       0.85      0.85      0.85       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "X= data4.drop('Class', axis=1)\n",
    "y= data4['Class']\n",
    "# ensure all data are floating point values\n",
    "\n",
    "# encode strings to integer\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42) # 70% training and 30% test\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(300,200,100), activation='relu', \n",
    "                    max_iter = 200, solver = 'adam')\n",
    "# Train the classifier with the traning data\n",
    "mlp.fit(X_train,y_train)\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"C:/Users/Mahmood/Desktop/Camparsion/BreastCancer/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/geneselected/Structure_Combine.csv\") \n",
    "data2.plot(kind='scatter',x='MKI67',y='FOXA1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOXA1</th>\n",
       "      <th>MKI67</th>\n",
       "      <th>KIF4A</th>\n",
       "      <th>EXO1</th>\n",
       "      <th>NCAPG</th>\n",
       "      <th>PLK1</th>\n",
       "      <th>HJURP</th>\n",
       "      <th>CACHD1</th>\n",
       "      <th>FAM189A2</th>\n",
       "      <th>GATA3</th>\n",
       "      <th>...</th>\n",
       "      <th>BUB1B</th>\n",
       "      <th>FOXC1</th>\n",
       "      <th>CENPA</th>\n",
       "      <th>CDCA8</th>\n",
       "      <th>CEP55</th>\n",
       "      <th>FOXM1</th>\n",
       "      <th>BUB1</th>\n",
       "      <th>KIF2C</th>\n",
       "      <th>CDC20</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9889.624302</td>\n",
       "      <td>5761.784552</td>\n",
       "      <td>970.577765</td>\n",
       "      <td>797.864530</td>\n",
       "      <td>1011.653834</td>\n",
       "      <td>1337.478514</td>\n",
       "      <td>346.737485</td>\n",
       "      <td>50.140344</td>\n",
       "      <td>63.088275</td>\n",
       "      <td>9809.065612</td>\n",
       "      <td>...</td>\n",
       "      <td>708.684655</td>\n",
       "      <td>23.069263</td>\n",
       "      <td>148.425998</td>\n",
       "      <td>634.510400</td>\n",
       "      <td>1176.511739</td>\n",
       "      <td>2063.245817</td>\n",
       "      <td>678.074509</td>\n",
       "      <td>812.824456</td>\n",
       "      <td>1040.311599</td>\n",
       "      <td>LumB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2157.881611</td>\n",
       "      <td>299.414442</td>\n",
       "      <td>44.492800</td>\n",
       "      <td>30.524590</td>\n",
       "      <td>65.977399</td>\n",
       "      <td>74.017782</td>\n",
       "      <td>38.141773</td>\n",
       "      <td>703.545540</td>\n",
       "      <td>1219.691015</td>\n",
       "      <td>3210.539426</td>\n",
       "      <td>...</td>\n",
       "      <td>54.345927</td>\n",
       "      <td>279.731711</td>\n",
       "      <td>23.221673</td>\n",
       "      <td>71.476644</td>\n",
       "      <td>69.252776</td>\n",
       "      <td>140.721602</td>\n",
       "      <td>67.982900</td>\n",
       "      <td>71.476644</td>\n",
       "      <td>134.019582</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3843.220403</td>\n",
       "      <td>1865.956968</td>\n",
       "      <td>738.114080</td>\n",
       "      <td>301.183724</td>\n",
       "      <td>434.345717</td>\n",
       "      <td>1176.919557</td>\n",
       "      <td>393.140178</td>\n",
       "      <td>98.674131</td>\n",
       "      <td>25.300605</td>\n",
       "      <td>345.489966</td>\n",
       "      <td>...</td>\n",
       "      <td>530.938151</td>\n",
       "      <td>433.623760</td>\n",
       "      <td>261.632871</td>\n",
       "      <td>682.365076</td>\n",
       "      <td>519.867444</td>\n",
       "      <td>1701.392165</td>\n",
       "      <td>448.884354</td>\n",
       "      <td>760.023386</td>\n",
       "      <td>1490.416670</td>\n",
       "      <td>Basal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2687.036121</td>\n",
       "      <td>151.870726</td>\n",
       "      <td>20.130345</td>\n",
       "      <td>20.999746</td>\n",
       "      <td>39.656900</td>\n",
       "      <td>29.260855</td>\n",
       "      <td>24.477766</td>\n",
       "      <td>1122.733652</td>\n",
       "      <td>748.832894</td>\n",
       "      <td>2978.767899</td>\n",
       "      <td>...</td>\n",
       "      <td>24.477766</td>\n",
       "      <td>762.714861</td>\n",
       "      <td>44.477383</td>\n",
       "      <td>40.129743</td>\n",
       "      <td>37.957156</td>\n",
       "      <td>63.880336</td>\n",
       "      <td>24.043916</td>\n",
       "      <td>42.303350</td>\n",
       "      <td>55.349562</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6603.430556</td>\n",
       "      <td>1106.125986</td>\n",
       "      <td>659.441102</td>\n",
       "      <td>235.535384</td>\n",
       "      <td>683.406424</td>\n",
       "      <td>868.270044</td>\n",
       "      <td>498.621057</td>\n",
       "      <td>40.487369</td>\n",
       "      <td>9.087604</td>\n",
       "      <td>8001.750889</td>\n",
       "      <td>...</td>\n",
       "      <td>322.979771</td>\n",
       "      <td>60.943481</td>\n",
       "      <td>193.675815</td>\n",
       "      <td>424.405635</td>\n",
       "      <td>376.367958</td>\n",
       "      <td>1026.700730</td>\n",
       "      <td>322.130175</td>\n",
       "      <td>531.932730</td>\n",
       "      <td>622.314478</td>\n",
       "      <td>LumB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>6344.980434</td>\n",
       "      <td>741.601319</td>\n",
       "      <td>219.412210</td>\n",
       "      <td>141.229729</td>\n",
       "      <td>179.818793</td>\n",
       "      <td>155.223158</td>\n",
       "      <td>116.484970</td>\n",
       "      <td>427.061490</td>\n",
       "      <td>319.129906</td>\n",
       "      <td>13778.201870</td>\n",
       "      <td>...</td>\n",
       "      <td>222.876392</td>\n",
       "      <td>180.318049</td>\n",
       "      <td>38.298076</td>\n",
       "      <td>205.785854</td>\n",
       "      <td>110.025949</td>\n",
       "      <td>338.262632</td>\n",
       "      <td>248.827133</td>\n",
       "      <td>186.056889</td>\n",
       "      <td>242.375489</td>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>7223.588525</td>\n",
       "      <td>1600.159499</td>\n",
       "      <td>400.567066</td>\n",
       "      <td>412.428437</td>\n",
       "      <td>654.160120</td>\n",
       "      <td>225.330688</td>\n",
       "      <td>247.056979</td>\n",
       "      <td>345.825394</td>\n",
       "      <td>195.428898</td>\n",
       "      <td>10879.314230</td>\n",
       "      <td>...</td>\n",
       "      <td>644.305009</td>\n",
       "      <td>206.428735</td>\n",
       "      <td>135.317067</td>\n",
       "      <td>271.611358</td>\n",
       "      <td>623.220984</td>\n",
       "      <td>737.295939</td>\n",
       "      <td>1047.039388</td>\n",
       "      <td>228.159672</td>\n",
       "      <td>302.082751</td>\n",
       "      <td>LumB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>2271.453411</td>\n",
       "      <td>1023.858053</td>\n",
       "      <td>186.082684</td>\n",
       "      <td>98.708335</td>\n",
       "      <td>219.244980</td>\n",
       "      <td>129.230250</td>\n",
       "      <td>95.266693</td>\n",
       "      <td>1568.315389</td>\n",
       "      <td>670.967929</td>\n",
       "      <td>2694.122994</td>\n",
       "      <td>...</td>\n",
       "      <td>200.742183</td>\n",
       "      <td>785.898942</td>\n",
       "      <td>36.194536</td>\n",
       "      <td>145.724536</td>\n",
       "      <td>175.253567</td>\n",
       "      <td>237.650891</td>\n",
       "      <td>214.881877</td>\n",
       "      <td>103.142850</td>\n",
       "      <td>311.351410</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>2390.671187</td>\n",
       "      <td>1253.894280</td>\n",
       "      <td>758.234347</td>\n",
       "      <td>421.707830</td>\n",
       "      <td>519.039311</td>\n",
       "      <td>970.443224</td>\n",
       "      <td>306.703326</td>\n",
       "      <td>202.334707</td>\n",
       "      <td>525.555750</td>\n",
       "      <td>868.751648</td>\n",
       "      <td>...</td>\n",
       "      <td>418.359678</td>\n",
       "      <td>4302.322628</td>\n",
       "      <td>166.733478</td>\n",
       "      <td>477.481160</td>\n",
       "      <td>485.726369</td>\n",
       "      <td>906.208995</td>\n",
       "      <td>747.899184</td>\n",
       "      <td>397.800147</td>\n",
       "      <td>519.183239</td>\n",
       "      <td>Basal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>36.307608</td>\n",
       "      <td>7077.381631</td>\n",
       "      <td>2722.657891</td>\n",
       "      <td>1459.440824</td>\n",
       "      <td>2132.012232</td>\n",
       "      <td>2284.559022</td>\n",
       "      <td>1036.640537</td>\n",
       "      <td>176.362497</td>\n",
       "      <td>142.231776</td>\n",
       "      <td>132.220311</td>\n",
       "      <td>...</td>\n",
       "      <td>1093.698978</td>\n",
       "      <td>3027.476403</td>\n",
       "      <td>876.615270</td>\n",
       "      <td>2679.967890</td>\n",
       "      <td>1548.654925</td>\n",
       "      <td>5582.516907</td>\n",
       "      <td>2298.855389</td>\n",
       "      <td>2725.868026</td>\n",
       "      <td>4087.208144</td>\n",
       "      <td>Basal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           FOXA1        MKI67        KIF4A         EXO1        NCAPG  \\\n",
       "0    9889.624302  5761.784552   970.577765   797.864530  1011.653834   \n",
       "1    2157.881611   299.414442    44.492800    30.524590    65.977399   \n",
       "2    3843.220403  1865.956968   738.114080   301.183724   434.345717   \n",
       "3    2687.036121   151.870726    20.130345    20.999746    39.656900   \n",
       "4    6603.430556  1106.125986   659.441102   235.535384   683.406424   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "959  6344.980434   741.601319   219.412210   141.229729   179.818793   \n",
       "960  7223.588525  1600.159499   400.567066   412.428437   654.160120   \n",
       "961  2271.453411  1023.858053   186.082684    98.708335   219.244980   \n",
       "962  2390.671187  1253.894280   758.234347   421.707830   519.039311   \n",
       "963    36.307608  7077.381631  2722.657891  1459.440824  2132.012232   \n",
       "\n",
       "            PLK1        HJURP       CACHD1     FAM189A2         GATA3  ...  \\\n",
       "0    1337.478514   346.737485    50.140344    63.088275   9809.065612  ...   \n",
       "1      74.017782    38.141773   703.545540  1219.691015   3210.539426  ...   \n",
       "2    1176.919557   393.140178    98.674131    25.300605    345.489966  ...   \n",
       "3      29.260855    24.477766  1122.733652   748.832894   2978.767899  ...   \n",
       "4     868.270044   498.621057    40.487369     9.087604   8001.750889  ...   \n",
       "..           ...          ...          ...          ...           ...  ...   \n",
       "959   155.223158   116.484970   427.061490   319.129906  13778.201870  ...   \n",
       "960   225.330688   247.056979   345.825394   195.428898  10879.314230  ...   \n",
       "961   129.230250    95.266693  1568.315389   670.967929   2694.122994  ...   \n",
       "962   970.443224   306.703326   202.334707   525.555750    868.751648  ...   \n",
       "963  2284.559022  1036.640537   176.362497   142.231776    132.220311  ...   \n",
       "\n",
       "           BUB1B        FOXC1       CENPA        CDCA8        CEP55  \\\n",
       "0     708.684655    23.069263  148.425998   634.510400  1176.511739   \n",
       "1      54.345927   279.731711   23.221673    71.476644    69.252776   \n",
       "2     530.938151   433.623760  261.632871   682.365076   519.867444   \n",
       "3      24.477766   762.714861   44.477383    40.129743    37.957156   \n",
       "4     322.979771    60.943481  193.675815   424.405635   376.367958   \n",
       "..           ...          ...         ...          ...          ...   \n",
       "959   222.876392   180.318049   38.298076   205.785854   110.025949   \n",
       "960   644.305009   206.428735  135.317067   271.611358   623.220984   \n",
       "961   200.742183   785.898942   36.194536   145.724536   175.253567   \n",
       "962   418.359678  4302.322628  166.733478   477.481160   485.726369   \n",
       "963  1093.698978  3027.476403  876.615270  2679.967890  1548.654925   \n",
       "\n",
       "           FOXM1         BUB1        KIF2C        CDC20   Class  \n",
       "0    2063.245817   678.074509   812.824456  1040.311599    LumB  \n",
       "1     140.721602    67.982900    71.476644   134.019582  Normal  \n",
       "2    1701.392165   448.884354   760.023386  1490.416670   Basal  \n",
       "3      63.880336    24.043916    42.303350    55.349562  Normal  \n",
       "4    1026.700730   322.130175   531.932730   622.314478    LumB  \n",
       "..           ...          ...          ...          ...     ...  \n",
       "959   338.262632   248.827133   186.056889   242.375489    LumA  \n",
       "960   737.295939  1047.039388   228.159672   302.082751    LumB  \n",
       "961   237.650891   214.881877   103.142850   311.351410  Normal  \n",
       "962   906.208995   747.899184   397.800147   519.183239   Basal  \n",
       "963  5582.516907  2298.855389  2725.868026  4087.208144   Basal  \n",
       "\n",
       "[964 rows x 24 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: encoder7.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ed6ab832430f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# load the model from file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'encoder7.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;31m# encode the train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mX_train_encode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m       \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    108\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[0;32m    111\u001b[0m                   (export_dir,\n\u001b[0;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: encoder7.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "# evaluate logistic regression on encoded input\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# define dataset\n",
    "path = 'C:/Users/Mahmood/Desktop/Final_DataSet/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/RNA-seq_BreastDataStructured1.csv'\n",
    "df = pd.read_csv(path)\n",
    "df=df.drop(['sample'], axis=1)\n",
    "X= df.drop('Class', axis=1)\n",
    "y= df['Class']\n",
    "X = X.astype('float32')\n",
    "# encode strings to integer\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "# load the model from file\n",
    "encoder = load_model('encoder7.h5')\n",
    "# encode the train data\n",
    "X_train_encode = encoder.predict(X_train)\n",
    "# encode the test data\n",
    "X_test_encode = encoder.predict(X_test)\n",
    "# define the model\n",
    "model = DecisionTreeClassifier(max_depth = 2)\n",
    "# fit the model on the training set\n",
    "model.fit(X_train_encode, y_train)\n",
    "# make predictions on the test set\n",
    "yhat = model.predict(X_test_encode)\n",
    "# calculate classification accuracy\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print(acc)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "# define dataset\n",
    "path = 'C:/Users/Mahmood/Desktop/Final_DataSet/RNA-seq/BreastCancer/BreastCancerSutypes/Orginal/StructureData/RNA-seq_BreastDataStructured1.csv'\n",
    "df = pd.read_csv(path)\n",
    "df=df.drop(['sample'], axis=1)\n",
    "X= df.drop('Class', axis=1)\n",
    "y= df['Class']\n",
    "X = X.astype('float32')\n",
    "# number of input columns\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "n_inputs = X.shape[1]\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "# define encoder\n",
    "visible = Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "e = Dense(n_inputs*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# encoder level 2\n",
    "e = Dense(n_inputs)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# bottleneck\n",
    "n_bottleneck = n_inputs\n",
    "bottleneck = Dense(n_bottleneck)(e)\n",
    "# define decoder, level 1\n",
    "d = Dense(n_inputs)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# decoder level 2\n",
    "d = Dense(n_inputs*2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(d)\n",
    "# define autoencoder model\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# plot the autoencoder\n",
    "plot_model(model, 'autoencoder_no_compress.png', show_shapes=True)\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=200, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n",
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# define an encoder model (without the decoder)\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "plot_model(encoder, 'encoder_no_compress.png', show_shapes=True)\n",
    "# save the encoder to file\n",
    "encoder.save('encoder7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
